# 3. Set the value of the inverse
setInverse <- function(inverse) inv <<- inverse
# 4. Get the value of the inverse
getInverse <- function() inv
list(set = set, get = get,
setInverse = setInverse, getInverse = getInverse)
}
## This second function, cacheSolve computes the inverse of the special "matrix"
## from the makeCacheMatrix above. We'll know if this actually works if when the
## matrix has not changed, the function pulls from the cache instead of
## computing the answer from scratch again.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if (!is.null(inv)) {
message("getting cached data")
return(inv)
}
mat <- x$get()
inv <- solve(mat, ...)
x$setInverse(inv)
## Return a matrix that is the inverse of 'x'
inv
}
x <- matrix(rnorm(16), nrow = 4)
cx <- makeCacheMatrix(x)
cx$get()
cacheSolve(cx)
cacheSolve(cx)
cacheSolve(cx)
cacheSolve(cx)
## Programming Assignment 2 - Caching the Inverse of a Matrix
## Caching allows us to reclaim valuable computational time especially with
## typically time-intensive procedures like Matrix inversion. That way, there
## is no need to compute the result for the same matrix over and over--provided,
## of course, that the matrix stays the same.It's like visiting the same web-
## page over and over. The page loads faster usually because it is pulling from
## the cache as opposed to the
## The idea of this exercise is to develop a couple functions that not only
## store a matrix but also caches its result..
## The first function, makeCacheMatrix creates an object that can cache its
## inverse according to the steps outlined in the assignment guide:
## 1. Set the value of the matrix
## 2. Get the value of the matrix
## 3. Set the value of the inverse
## 4. Get the value of the inverse
makeCacheMatrix <- function(x = matrix()) {
# store the cached inverse matrix
inv <- NULL
# 1. Set the value of the matrix
set <- function(y) {
x <<- y
inv <<- NULL
}
# 2. Get the value of the matrix
get <- function() x
# 3. Set the value of the inverse
setInverse <- function(inverse) inv <<- inverse
# 4. Get the value of the inverse
getInverse <- function() inv
list(set = set, get = get,
setInverse = setInverse, getInverse = getInverse)
}
## This second function, cacheSolve computes the inverse of the special "matrix"
## from the makeCacheMatrix above. We'll know if this actually works if when the
## matrix has not changed, the function pulls from the cache instead of
## computing the answer from scratch again.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if (!is.null(inv)) {
message("Utilizing cached data instead...")
return(inv)
}
mat <- x$get()
inv <- solve(mat, ...)
x$setInverse(inv)
## Return a matrix that is the inverse of 'x'
inv
}
cacheSolve(cx)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
x1 <- 9
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
x2 <- 8
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
?qbinom
?rbinom
library(swirl)
rm(list=ls())
library(swirl)
set.seed(13435)
x <- data.frame("var1"=sample(1:5),"var2"+sample(6:10),"var3"=sample(11:15))
x <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x <- x[sample(1:5),]; x$cvar2[c(1,3)]=NA
x <- x[sample(1:5),]; x$var2[c(1,3)]=NA
x
x[,1]
x[,"var3"]
x[1:2,"var2"]
x[1:3,"var2"]
x[which(x$var2 > 8)]
x[which(x$var2 > 8),]
x[which(x$var2 >= 8),]
library(plyr)
arrange(x,var1)
x$var4 <- rnorm(5)
x
y <- cbind(x,rnorm(5))
y
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
chicago <- readRDS("chicago.rds")
which(agricultureLogical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
f <- file.path(getwd(), "ss06hid.csv")
download.file(url, f)
dt <- data.table(read.csv(f))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
which(agricultureLogical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
f <- file.path(getwd(), "ss06hid.csv")
download.file(url, f)
dt <- data.table(read.csv(f))
?data.table
library(dplyr)
dplyr
library(data.table)
dt <- data.table(read.csv(f))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
which(agricultureLogical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
f <- file.path(getwd(), "jeff.jpg")
download.file(url, f, mode = "wb")
img <- readJPEG(f, native = TRUE)
quantile(img, probs = c(0.3, 0.8))
?readJPEG
library(jpeg)
install.packages("jpeg")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
f <- file.path(getwd(), "jeff.jpg")
download.file(url, f, mode = "wb")
img <- readJPEG(f, native = TRUE)
quantile(img, probs = c(0.3, 0.8))
library(jpeg)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
f <- file.path(getwd(), "jeff.jpg")
download.file(url, f, mode = "wb")
img <- readJPEG(f, native = TRUE)
quantile(img, probs = c(0.3, 0.8))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip = 4, nrows = 215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
dt
[,dt]
dt[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp)][13]
dt[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(dt$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
dt$quantileGDP <- cut(dt$rankingGDP, breaks = breaks)
dt[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
library(swirl)
rm(list=ls())
swirl/9
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12 1975")
dmy(25081985)
ymd("192012")
ymd("1920-01-02")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 11, minutes = 19)
this_moment
nyc <- now()
nyc <- now("America/New_York")
nyc
x <- rnorm(100)
hist(x)
y <- rnorm(100)
plot (x,y)
z <- rnorm(100)
plot(x,z)
plot(x,y)
par(mar=C(2,2,2,2,2))
par(mar=C(2,2,2,2))
setwd("C:/plodder/k0d3r/Data Science Specialization/docs/5 - Reproducible Research/RepData_PeerAssessment1")
unzip("activity.zip")
data <- read.csv("activity.csv", colClasses = c("integer", "Date", "factor"))
data$month <- as.numeric(format(data$date, "%m"))
noNA <- na.omit(data)
rownames(noNA) <- 1:nrow(noNA)
head(noNA)
dim(noNA)
library(ggplot2)
ggplot(noNA, aes(date, steps)) + geom_bar(stat = "identity", colour = "steelblue", fill = "steelblue", width = 0.7) + facet_grid(. ~ month, scales = "free") + labs(title = "Histogram of Total Number of Steps Taken Each Day", x = "Date", y = "Total number of steps")
unzip("activity.zip")
data <- read.csv("activity.csv", colClasses = c("integer", "Date", "factor"))
data$month <- as.numeric(format(data$date, "%m"))
noNA <- na.omit(data)
rownames(noNA) <- 1:nrow(noNA)
head(noNA)
dim(noNA)
library(ggplot2)
ggplot(noNA, aes(date, steps)) + geom_bar(stat = "identity", colour = "steelblue", fill = "steelblue", width = 0.7) + facet_grid(. ~ month, scales = "free") + labs(title = "Histogram of Total Number of Steps Taken Each Day", x = "Date", y = "Total number of steps")
totalSteps <- aggregate(noNA$steps, list(Date = noNA$date), FUN = "sum")$x
mean(totalSteps)
median(totalSteps)
avgSteps <- aggregate(noNA$steps, list(interval = as.numeric(as.character(noNA$interval))), FUN = "mean")
names(avgSteps)[2] <- "meanOfSteps"
ggplot(avgSteps, aes(interval, meanOfSteps)) + geom_line(color = "steelblue", size = 0.8) + labs(title = "Time Series Plot of the 5-minute Interval", x = "5-minute intervals", y = "Average Number of Steps Taken")
avgSteps[avgSteps$meanOfSteps == max(avgSteps$meanOfSteps), ]
sum(is.na(data))
newData <- data
for (i in 1:nrow(newData)) {
if (is.na(newData$steps[i])) {
newData$steps[i] <- avgSteps[which(newData$interval[i] == avgSteps$interval), ]$meanOfSteps
}
}
head(newData)
sum(is.na(newData))
ggplot(newData, aes(date, steps)) + geom_bar(stat = "identity",
colour = "steelblue",
fill = "steelblue",
width = 0.7) + facet_grid(. ~ month, scales = "free") + labs(title = "Histogram of Total Number of Steps Taken Each Day (no missing data)", x = "Date", y = "Total number of steps")
newTotalSteps <- aggregate(newData$steps,
list(Date = newData$date),
FUN = "sum")$x
newMean <- mean(newTotalSteps)
newMean
newMedian <- median(newTotalSteps)
newMedian
oldMean <- mean(totalSteps)
oldMedian <- median(totalSteps)
newMean - oldMean
newMedian - oldMedian
head(newData)
newData$weekdays <- factor(format(newData$date, "%A"))
levels(newData$weekdays)
levels(newData$weekdays) <- list(weekday = c("Monday", "Tuesday",
"Wednesday",
"Thursday", "Friday"),
weekend = c("Saturday", "Sunday"))
levels(newData$weekdays)
table(newData$weekdays)
avgSteps <- aggregate(newData$steps,
list(interval = as.numeric(as.character(newData$interval)),
weekdays = newData$weekdays),
FUN = "mean")
names(avgSteps)[3] <- "meanOfSteps"
library(lattice)
xyplot(avgSteps$meanOfSteps ~ avgSteps$interval | avgSteps$weekdays,
layout = c(1, 2), type = "l",
xlab = "Interval", ylab = "Number of steps")
---
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
```r
unzip("activity.zip")
data <- read.csv("activity.csv", colClasses = c("integer", "Date", "factor"))
data$month <- as.numeric(format(data$date, "%m"))
noNA <- na.omit(data)
rownames(noNA) <- 1:nrow(noNA)
head(noNA)
```
```
##   steps       date interval month
## 1     0 2012-10-02        0    10
## 2     0 2012-10-02        5    10
## 3     0 2012-10-02       10    10
## 4     0 2012-10-02       15    10
## 5     0 2012-10-02       20    10
## 6     0 2012-10-02       25    10
```
```r
dim(noNA)
```
```
## [1] 15264     4
```
```r
library(ggplot2)
```
```
## Warning: package 'ggplot2' was built under R version 3.4.1
```
## What is the mean total number of steps taken per day?
For this part of the assignment, you can ignore the missing values in the dataset.
* Make a histogram of the total number of steps taken each day
```r
ggplot(noNA, aes(date, steps)) + geom_bar(stat = "identity", colour = "sienna2", fill = "sienna2", width = 0.65) + facet_grid(. ~ month, scales = "free") + labs(title = "Histogram of Total Number of Steps Taken Each Day", x = "Date", y = "Total number of steps")
```
![](PA1_template_files/figure-html/unnamed-chunk-2-1.png)<!-- -->
* Calculate and report the mean and median total number of steps taken per day
Mean total number of steps taken per day:
```r
totalSteps <- aggregate(noNA$steps, list(Date = noNA$date), FUN = "sum")$x
mean(totalSteps)
```
```
## [1] 10766.19
```
Median total number of steps taken per day:
```r
median(totalSteps)
```
```
## [1] 10765
```
## What is the average daily activity pattern?
* Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```r
avgSteps <- aggregate(noNA$steps, list(interval = as.numeric(as.character(noNA$interval))), FUN = "mean")
names(avgSteps)[2] <- "meanOfSteps"
ggplot(avgSteps, aes(interval, meanOfSteps)) + geom_line(color = "sienna2", size = 0.75) + labs(title = "Time Series Plot of the 5-minute Interval", x = "5-minute Intervals", y = "Average Number of Steps Taken")
```
![](PA1_template_files/figure-html/unnamed-chunk-5-1.png)<!-- -->
* Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
```r
avgSteps[avgSteps$meanOfSteps == max(avgSteps$meanOfSteps), ]
```
```
##     interval meanOfSteps
## 104      835    206.1698
```
## Imputing missing values
* The total number of rows with NAs:
```r
sum(is.na(data))
```
```
## [1] 2304
```
* Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
I am not sure but using the mean to fill in the missing values sounds good to me.
* Create a new dataset that is equal to the original dataset but with the missing data filled in.
```r
newData <- data
for (i in 1:nrow(newData)) {
if (is.na(newData$steps[i])) {
newData$steps[i] <- avgSteps[which(newData$interval[i] == avgSteps$interval), ]$meanOfSteps
}
}
head(newData)
```
```
##       steps       date interval month
## 1 1.7169811 2012-10-01        0    10
## 2 0.3396226 2012-10-01        5    10
## 3 0.1320755 2012-10-01       10    10
## 4 0.1509434 2012-10-01       15    10
## 5 0.0754717 2012-10-01       20    10
## 6 2.0943396 2012-10-01       25    10
```
```r
sum(is.na(newData))
```
```
## [1] 0
```
* Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day.
```r
ggplot(newData, aes(date, steps)) + geom_bar(stat = "identity",
colour = "sienna2",
fill = "sienna2",
width = 0.65) + facet_grid(. ~ month, scales = "free") + labs(title = "Histogram of Total Number of Steps Taken Each Day (no missing data)", x = "Date", y = "Total number of steps")
```
![](PA1_template_files/figure-html/unnamed-chunk-9-1.png)<!-- -->
* Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?
Mean total number of steps taken per day:
```r
newTotalSteps <- aggregate(newData$steps,
list(Date = newData$date),
FUN = "sum")$x
newMean <- mean(newTotalSteps)
newMean
```
```
## [1] 10766.19
```
Median total number of steps taken per day:
```r
newMedian <- median(newTotalSteps)
newMedian
```
```
## [1] 10766.19
```
Compare them with the two before imputing missing data:
```r
oldMean <- mean(totalSteps)
oldMedian <- median(totalSteps)
newMean - oldMean
```
```
## [1] 0
```
```r
newMedian - oldMedian
```
```
## [1] 1.188679
```
So, after imputing the missing data, the new mean of total steps taken per day is the same as that of the old mean; the new median of total steps taken per day is greater than that of the old median.
## Are there differences in activity patterns between weekdays and weekends?
* Create a new factor variable in the dataset with two levels -- "weekday" and "weekend" indicating whether a given date is a weekday or weekend day.
```r
head(newData)
```
```
##       steps       date interval month
## 1 1.7169811 2012-10-01        0    10
## 2 0.3396226 2012-10-01        5    10
## 3 0.1320755 2012-10-01       10    10
## 4 0.1509434 2012-10-01       15    10
## 5 0.0754717 2012-10-01       20    10
## 6 2.0943396 2012-10-01       25    10
```
```r
newData$weekdays <- factor(format(newData$date, "%A"))
levels(newData$weekdays)
```
```
## [1] "Friday"    "Monday"    "Saturday"  "Sunday"    "Thursday"  "Tuesday"
## [7] "Wednesday"
```
```r
levels(newData$weekdays) <- list(weekday = c("Monday", "Tuesday",
"Wednesday",
"Thursday", "Friday"),
weekend = c("Saturday", "Sunday"))
levels(newData$weekdays)
```
```
## [1] "weekday" "weekend"
```
```r
table(newData$weekdays)
```
```
##
## weekday weekend
##   12960    4608
```
* Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis).
```r
avgSteps <- aggregate(newData$steps,
list(interval = as.numeric(as.character(newData$interval)),
weekdays = newData$weekdays),
FUN = "mean")
names(avgSteps)[3] <- "meanOfSteps"
library(lattice)
xyplot(avgSteps$meanOfSteps ~ avgSteps$interval | avgSteps$weekdays,
layout = c(1, 2), type = "l",
xlab = "Interval", ylab = "Number of steps")
```
![](PA1_template_files/figure-html/unnamed-chunk-14-1.png)<!-- -->
